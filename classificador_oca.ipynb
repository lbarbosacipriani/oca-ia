{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb18702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (12.1.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.4.2)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: timm in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.0.24)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (8.1.8)\n",
      "Requirement already satisfied: widgetsnbextension in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (4.0.15)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (3.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (80.10.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2026.1.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in ./.venv/lib/python3.13/site-packages (from cuda-bindings==12.9.4->torch->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.25.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (1.3.5)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (3.0.16)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (26.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (4.67.2)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (0.21.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface_hub->timm->-r requirements.txt (line 6)) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22170478",
   "metadata": {},
   "source": [
    "## Exemplo de classificador com leitura do CSV. \n",
    "\n",
    "Etapas:\n",
    "\n",
    "- Leitura CSV.\n",
    "- Tratamento de imagens com lib PIL. \n",
    "- Leitura imagem. \n",
    "- Aplicacao Filtro para remocao background\n",
    "\n",
    "\n",
    "Input do modelo : (Imagem, sexo, idade, etnia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de731cfa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9688a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criacao de pastas output e models se nao existirem\n",
    "import os\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ca2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.ImageFIlter import treat_image_PIL\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import  DataLoader, TensorDataset, Dataset\n",
    "from torch import nn\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd08e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geracao dataset com aleatorio\n",
    "ds_file = pd.read_csv('dataset/exemplo_csv_2.csv')\n",
    "arr = np.random.choice([0, 1], size=216)\n",
    "\n",
    "ds_file = ds_file[['path','image_id','ID','IDADE','SEXO','ETNIA']]\n",
    "ds_file['oca'] = arr\n",
    "ds_file.to_csv('dataset/oca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c59064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file = pd.read_csv('dataset/oca.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52323b9c",
   "metadata": {},
   "source": [
    "## Geracao Tensor com imagens filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eaf296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop\n",
    "img_dataset = np.ones((ds_file.shape[0],3,256,256),dtype=np.uint8)\n",
    "\n",
    "j=0\n",
    "for i in ds_file['path']:\n",
    "    img_dataset[j]=treat_image_PIL('dataset/path/'+i,2)\n",
    "    j+=1\n",
    "tensor_imagem = torch.tensor(img_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c242f0e",
   "metadata": {},
   "source": [
    "## Geracao Tensor Age, sex, Etinia\n",
    "\n",
    "Encoding: \n",
    "\n",
    "- Sexo: M=0 F=1\n",
    "\n",
    "- Idade: Normalizar? Sim, dividir por 100 igual o artigo do Marco e Felipe fizeram. \n",
    "\n",
    "- Etnia: Encoding simples de categorias. Utilizaremos o Label Encoding para isso "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aec203",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b39994",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_id_sex_et= ds_file[['IDADE', 'SEXO', 'ETNIA']]\n",
    "ds_id_sex_et['SEXO'] = ds_file['SEXO'].map({ 'M':0, 'F':1})\n",
    "ds_id_sex_et['IDADE'] = ds_file['IDADE']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc21ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>ETNIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IDADE  SEXO  ETNIA\n",
       "0     0.85     0      1\n",
       "1     0.32     1      1\n",
       "2     0.60     1      1\n",
       "3     0.57     1      4\n",
       "4     0.57     1      1\n",
       "..     ...   ...    ...\n",
       "211   0.35     1      3\n",
       "212   0.72     0      2\n",
       "213   0.71     1      2\n",
       "214   0.49     0      2\n",
       "215   0.19     1      3\n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encoding variavel ETNIA -> Usando label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a sample dataframe with categorical data\n",
    "\n",
    "#print(f\"Before Encoding the Data:\\n\\n{ds_id_sex_et['ETNIA']}\\n\")\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "ds_id_sex_et['ETNIA'] = le.fit_transform(ds_id_sex_et['ETNIA'])\n",
    "ds_id_sex_et"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dbdca",
   "metadata": {},
   "source": [
    "## Geracao de rótulos para classificação\n",
    "\n",
    "Colunas utilizadas para classificacao (Labels)\n",
    "\n",
    "labels = [ OCA, NOCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd06990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "ds_file.columns\n",
    "labels = [ 'oca']\n",
    "ds_labels = ds_file[labels]\n",
    "ds_labels=ds_labels.astype(int)#,'False':0})\n",
    "tensor_label = torch.tensor(np.array(ds_labels))\n",
    "tensor_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9fcbf",
   "metadata": {},
   "source": [
    "### Resumo:\n",
    "\n",
    "model(tensor_imagem,ds_id_sex_et)\n",
    "\n",
    "labels : tensor_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc188221",
   "metadata": {},
   "source": [
    "## Criacao Subset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fdd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subset(Dataset):\n",
    "    r\"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): The whole Dataset\n",
    "        indices (sequence): Indices in the whole set selected for subset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes\n",
    "\n",
    "    def shape(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead13f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f0dcb69",
   "metadata": {},
   "source": [
    "## K-fold = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e96965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(tensor_imagem)\n",
    "print(kf)\n",
    "#for i in enumerate(kf.split(tensor_imagem)):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64652bf",
   "metadata": {},
   "source": [
    "## Criacao do dataset de treino e validacao com batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925d5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataset = TensorDataset(tensor_imagem, tensor_label)\n",
    "train_loader_img = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab916657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d682980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba835adf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addfb539",
   "metadata": {},
   "source": [
    "## Create a model to concat layers\n",
    "\n",
    "O modelo utilizado será o mesmo do artigo: Artificial Intelligence-Driven Screening System for Rapid Image-Based Classification of 12-Lead ECG Exams: A Promising Solution for Emergency Room Prioritization \n",
    "\n",
    "Desenvolvido conforme a figura abaixo: \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32068ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import ECGClassifierResnet\n",
    "\n",
    "class ECGClassifierResnet(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ECGClassifierResnet, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        #self.base_model = timm.create_model('efficientnet_b0', pretrained=True) \n",
    "        self.base_model=timm.create_model('resnet50d.ra4_e3600_r224_in1k',pretrained=True)\n",
    "        #self.base_model = timm.create_model('vit_mediumd_patch16_reg4_gap_256.sbb2_e200_in12k_ft_in1k',num_classes=5,pretrained=True)\n",
    "\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "\n",
    "        enet_out_size = 2048        # Make a classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(enet_out_size,1)\n",
    "        ) # saida como Sigmoid multilabel\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        #output = nn.Softmax(dim=1)(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c98c40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c198fcb9",
   "metadata": {},
   "source": [
    "## Train - Valid Loop\n",
    "\n",
    "Fluxo de treinamento\n",
    "\n",
    "Input: modelo, dataloader_train, dataloader_teste , epocas.\n",
    "- Para cada epoca\n",
    "\n",
    "    - treinamento:\n",
    "\n",
    "        - para cada batch (lote de imagens) no dataloader_train: (executo para todo o dataloader)\n",
    "            \n",
    "            leitura das imagens e rotulos. \n",
    "            \n",
    "            prediz o rotulo (outputs): rotulos preditos para o tamanho do batch (ex: para um batch de 10, o \n",
    "            output tem tamanho 10)\n",
    "            \n",
    "            calcula o Loss () \n",
    "            \n",
    "            aplica o backward -> Ajuste dos pesos nos neuronios de acordo com o valor de loss (w_{i})\n",
    "\n",
    "            otimizo o modelo com optimizer.step()\n",
    "\n",
    "    - validacao (avaliacao do desempenho para aquele conjunto de treinamento):\n",
    "        - para cada batch (lote de imagens) no dataloader_train: (executo para todo o dataloader)\n",
    "\n",
    "            leitura das imagens e rotulos.\n",
    "\n",
    "            prediz o rotulo (outputs): rotulos preditos para o tamanho do batch (ex: para um batch de 10, o \n",
    "            output tem tamanho 10)\n",
    "            \n",
    "            calcula o Loss ()\n",
    "\n",
    "\n",
    "    - Calculo de metricas de loss media de validacao.\n",
    "\n",
    "    - Calculo de metrica de loss media de treinamento. \n",
    "\n",
    "    - Print de metricas de desempenho para a epoca. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d61375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.empty(5)], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d209f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0e+000, 4.9e-324, 9.9e-324, 1.5e-323, 2.0e-323])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d5e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \" + str(device))\n",
    "def simple_loop(model, train_image, val_image, epochs):\n",
    "    # Simple training loop\n",
    "    num_epochs = epochs\n",
    "    train_losses, val_losses = [], []\n",
    "    lim_loss = 1.5\n",
    "    iter_size = 5\n",
    "    print(f'Number of training images per iteration: {iter_size}')\n",
    "    #model = modelo( num_classes=5)\n",
    "    model.to(device)\n",
    "    criterion =  nn.L1Loss()\n",
    "    #criterion =  nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    predict_label_full_epoch = []\n",
    "    predict_label_full = []\n",
    "    true_label_full_epoch = []\n",
    "    true_label_full = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        for images, labels in tqdm(train_image, desc='Training loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images = images.to(torch.float)\n",
    "            image, label = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image)\n",
    "            #print(outputs)\n",
    "            #print(label)\n",
    "            loss_train = criterion(outputs.float(), label.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss_train.item() * label.size(0)\n",
    "        train_loss = running_loss_train / len(train_image.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        running_loss_valid = 0.0\n",
    "        rotulos =[] \n",
    "        predict_label =[]\n",
    "        true_label =[]\n",
    "        _iter=0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_image, desc='Validation loop'):\n",
    "                # Move inputs and labels to the device\n",
    "                images = images.to(torch.float)\n",
    "                images, label = images.to(device), labels.to(device)\n",
    "                rotulos.append(label.cpu().data.numpy())\n",
    "                outputs = model(images)\n",
    "                loss_valid = criterion(outputs.float(), label.float())\n",
    "                #print( [outputs.cpu().data.numpy().astype(int).T[0]])\n",
    "                #print(label.cpu().data.numpy().astype(int).T[0])\n",
    "                #print(predict_label)\n",
    "                try:\n",
    "                    _pred = outputs.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "                    if(len(_pred) == iter_size):\n",
    "                        predict_label.append(_pred)\n",
    "                        _true = label.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "                        true_label.append(_true)\n",
    "                except Exception as e:\n",
    "                    print(f\"Concatenation error iter: {e}\")\n",
    "                    print(_pred)\n",
    "                    print(predict_label)    \n",
    "                running_loss_valid += loss_valid.item() * label.size(0)\n",
    "                _iter +=1\n",
    "        val_loss = running_loss_valid / len(val_image.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'End validation for epoch {epoch}')\n",
    "        print(f'Amount of images validated: {val_image}')\n",
    "        print(f'Label predict shape : {len(predict_label)} for epoch {epoch}')\n",
    "        print(f'Count of iterations: {_iter} for epoch {epoch}')\n",
    "        try:\n",
    "            _p = predict_label\n",
    "            _t = true_label\n",
    "            predict_label_full.append(_p)\n",
    "            true_label_full.append(_t)\n",
    "        except Exception as e:\n",
    "            print(f\"Concatenation error full: {e}\")\n",
    "            print(predict_label)\n",
    "            print(true_label)\n",
    "        #val_acc = accuracy_score(rotulos,output_model)\n",
    "        print(f'Val accuracy {epoch}:')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "\n",
    "    predict_label_full_out = np.array(predict_label_full)\n",
    "    true_label_full_out = np.array(true_label_full)\n",
    "\n",
    "    return train_losses, val_losses, model,predict_label_full_out, true_label_full_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34cda9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \" + str(device))\n",
    "def simple_loop(model, train_image, val_image, epochs):\n",
    "    # Simple training loop\n",
    "    num_epochs = epochs\n",
    "    train_losses, val_losses = [], []\n",
    "    lim_loss = 1.5\n",
    "    iter_size = (train_image.dataset.__len__())\n",
    "    print(f'Number of training iterations per epoch: {iter_size}')\n",
    "    #model = modelo( num_classes=5)\n",
    "    model.to(device)\n",
    "    criterion =  nn.L1Loss()\n",
    "    #criterion =  nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    predict_label_full = np.array([[1,1,1,1,1]], dtype=int)\n",
    "    predict_label_full = np.array([np.ones([5], dtype=int)])\n",
    "    true_label_full = np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "    true_label_full = np.array([np.ones([5], dtype=int)])\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        for images, labels in tqdm(train_image, desc='Training loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images = images.to(torch.float)\n",
    "            image, label = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image)\n",
    "            #print(outputs)\n",
    "            #print(label)\n",
    "            loss_train = criterion(outputs.float(), label.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss_train.item() * label.size(0)\n",
    "        train_loss = running_loss_train / len(train_image.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        running_loss_valid = 0.0\n",
    "        rotulos =[] \n",
    "        predict_label =np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "        predict_label =np.array([np.empty(5, dtype=int)])\n",
    "        predict_label =[]\n",
    "        true_label =np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "        true_label =np.array([np.empty(5, dtype=int)])\n",
    "        _iter=0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_image, desc='Validation loop'):\n",
    "                # Move inputs and labels to the device\n",
    "                images = images.to(torch.float)\n",
    "                images, label = images.to(device), labels.to(device)\n",
    "                rotulos.append(label.cpu().data.numpy())\n",
    "                outputs = model(images)\n",
    "                loss_valid = criterion(outputs.float(), label.float())\n",
    "                #print( [outputs.cpu().data.numpy().astype(int).T[0]])\n",
    "                #print(label.cpu().data.numpy().astype(int).T[0])\n",
    "                #print(predict_label)\n",
    "                try:\n",
    "                    _pred = [outputs.cpu().data.numpy().astype(int).T[0]]\n",
    "                    predict_label.append(_pred)\n",
    "                  #  print(_pred)\n",
    "                    if (_iter == 0):\n",
    "                        predict_label=_pred\n",
    "                    else:\n",
    "                        predict_label=np.concatenate((predict_label,_pred), axis=0)\n",
    "                  #  print(predict_label)\n",
    "                    _true = [label.cpu().data.numpy().astype(int).T[0]]\n",
    "                    true_label=np.concatenate((true_label, _true), axis=0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Concatenation error: {e}\")\n",
    "                    print(_pred)\n",
    "                    print(predict_label)    \n",
    "                running_loss_valid += loss_valid.item() * label.size(0)\n",
    "                _iter +=1\n",
    "        val_loss = running_loss_valid / len(val_image.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'End validation for epoch {epoch}')\n",
    "        print(f'Amount of images validated: {val_image}')\n",
    "        print(f'Label predict shape : {len(predict_label)} for epoch {epoch}')\n",
    "        print(f'Count of iterations: {_iter} for epoch {epoch}')\n",
    "        try:\n",
    "            predict_label_full=np.concatenate((predict_label_full,predict_label), axis=0)\n",
    "            true_label_full=np.concatenate((true_label_full,true_label), axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Concatenation error: {e}\")\n",
    "            print(predict_label)\n",
    "            print(true_label)\n",
    "        #val_acc = accuracy_score(rotulos,output_model)\n",
    "        print(f'Val accuracy {epoch}:')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "    \n",
    "    return train_losses, val_losses, model,predict_label_full, true_label_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "809e6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_model(model, path = 'output/modelos', name_file='model.pth'):\n",
    "    full_path = os.path.join(path, name_file)\n",
    "    torch.save(model.state_dict(), full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60622c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_metricas(path='output/metricas', name_file_train='train_loss_total.npy', name_file_val='val_loss_total.npy',predict_label=None, true_label=None):\n",
    "    full_path_train = os.path.join(path, name_file_train)\n",
    "    full_path_val = os.path.join(path, name_file_val)\n",
    "    np.save(full_path_train, np.array(predict_label))\n",
    "    np.save(full_path_val, np.array(true_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df8a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train and valid for Fold 0\n",
      "Number of training iterations per epoch: 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bc9c439f3b4689b667de86f661d154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7448bb162d794d5484d85e6ec4b56f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([2174, 2174, 2174, 2484, 2174])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([2174, 2241, 2174, 2174, 3527])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([2998, 3879, 2174, 2174, 2174])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([3989, 2174, 5323, 3555, 2174])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([2174, 4548, 2825, 2174, 4019])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])], [array([2174, 4548, 2825, 2174, 4019])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([2174, 2174, 2174, 2174, 2174])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])], [array([2174, 4548, 2825, 2174, 4019])], [array([2174, 2174, 2174, 2174, 2174])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([2174, 5297, 2174, 1830, 2174])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])], [array([2174, 4548, 2825, 2174, 4019])], [array([2174, 2174, 2174, 2174, 2174])], [array([2174, 5297, 2174, 1830, 2174])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([2175, 2175, 2175, 2175])]\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])], [array([2174, 4548, 2825, 2174, 4019])], [array([2174, 2174, 2174, 2174, 2174])], [array([2174, 5297, 2174, 1830, 2174])], [array([2175, 2175, 2175, 2175])]]\n",
      "End validation for epoch 0\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 0\n",
      "Count of iterations: 9 for epoch 0\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([2174, 2174, 4134, 7334, 2174]), [array([2174, 2174, 2174, 2484, 2174])], [array([2174, 2241, 2174, 2174, 3527])], [array([2998, 3879, 2174, 2174, 2174])], [array([3989, 2174, 5323, 3555, 2174])], [array([2174, 4548, 2825, 2174, 4019])], [array([2174, 2174, 2174, 2174, 2174])], [array([2174, 5297, 2174, 1830, 2174])], [array([2175, 2175, 2175, 2175])]]\n",
      "[[1 1 1 1 1]\n",
      " [0 1 1 0 0]]\n",
      "Val accuracy 0:\n",
      "Epoch 1/10 - Train loss: 0.6283480194938738, Validation loss: 2750.6977150656962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1874a44f2c4e6380b2108fbd4f5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a2aa941b6f4edeb3d4420926130c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([1, 1, 0, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([1, 1, 3, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([1, 0, 1, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 1, 1, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([0, 1, 1, 7, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])], [array([0, 1, 1, 7, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([1, 1, 6, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])], [array([0, 1, 1, 7, 1])], [array([1, 1, 6, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 1, 1, 1, 1])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])], [array([0, 1, 1, 7, 1])], [array([1, 1, 6, 1, 1])], [array([0, 1, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 2])]\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])], [array([0, 1, 1, 7, 1])], [array([1, 1, 6, 1, 1])], [array([0, 1, 1, 1, 1])], [array([1, 1, 1, 2])]]\n",
      "End validation for epoch 1\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 1\n",
      "Count of iterations: 9 for epoch 1\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 0, 1]), [array([1, 1, 0, 1, 1])], [array([1, 1, 3, 1, 1])], [array([1, 0, 1, 1, 1])], [array([0, 1, 1, 1, 1])], [array([0, 1, 1, 7, 1])], [array([1, 1, 6, 1, 1])], [array([0, 1, 1, 1, 1])], [array([1, 1, 1, 2])]]\n",
      "[[2174 2174 2174 2484 2174]\n",
      " [   0    1    0    1    1]]\n",
      "Val accuracy 1:\n",
      "Epoch 2/10 - Train loss: 0.5439467138155948, Validation loss: 1.3439900360324166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d8a0278d8b411c8b06f89c1e969681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad540e68acc432c8f2bd78c930f1026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 3])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([1, 0, 5, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 5, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 5, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 1, 0, 1, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 5, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 1, 0, 1, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 5, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 1, 0, 1, 0])], [array([0, 0, 0, 0])]]\n",
      "End validation for epoch 2\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 2\n",
      "Count of iterations: 9 for epoch 2\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 3])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 5, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 1, 0, 1, 0])], [array([0, 0, 0, 0])]]\n",
      "[[1 1 0 1 1]\n",
      " [0 0 0 1 0]]\n",
      "Val accuracy 2:\n",
      "Epoch 3/10 - Train loss: 0.490263348012123, Validation loss: 0.6750306890092113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b8c27f3ac844f794783c0236b0769f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545c3e4670f74874952b426b7c44620e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 4])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 1, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 1, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 1, 0])], [array([0, 0, 0, 0])]]\n",
      "End validation for epoch 3\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 3\n",
      "Count of iterations: 9 for epoch 3\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 4])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 1, 0])], [array([0, 0, 0, 0])]]\n",
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]]\n",
      "Val accuracy 3:\n",
      "Epoch 4/10 - Train loss: 0.5119403093013652, Validation loss: 0.5497741963375699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34355c70d318421b919a1c9db46642cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0785b32a451d4d3cb8741965fee8d7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([1, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([4, 0, 1, 0, 1])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([4, 0, 1, 0, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([4, 0, 1, 0, 1])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([4, 0, 1, 0, 1])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([4, 0, 1, 0, 1])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "End validation for epoch 4\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 4\n",
      "Count of iterations: 9 for epoch 4\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([1, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([4, 0, 1, 0, 1])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "[[0 0 0 0 0]\n",
      " [0 1 1 1 1]]\n",
      "Val accuracy 4:\n",
      "Epoch 5/10 - Train loss: 0.5311712877348412, Validation loss: 0.584976239637895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c102b2d28746db97e236b0b2f8887a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91c98ce07ba4b52b2c00416682e889d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 1, 1])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([ 1,  0, 19,  1,  0])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([0, 0, 1, 1, 1])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([1, 1, 0, 0, 0])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 1, 4])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])], [array([1, 1, 1, 1, 4])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([1, 8, 1, 1, 1])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])], [array([1, 1, 1, 1, 4])], [array([1, 8, 1, 1, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 0, 1])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])], [array([1, 1, 1, 1, 4])], [array([1, 8, 1, 1, 1])], [array([1, 1, 1, 0, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([1, 1, 1, 1])]\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])], [array([1, 1, 1, 1, 4])], [array([1, 8, 1, 1, 1])], [array([1, 1, 1, 0, 1])], [array([1, 1, 1, 1])]]\n",
      "End validation for epoch 5\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 5\n",
      "Count of iterations: 9 for epoch 5\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([ 1,  1, 11,  0,  0]), [array([1, 1, 1, 1, 1])], [array([ 1,  0, 19,  1,  0])], [array([0, 0, 1, 1, 1])], [array([1, 1, 0, 0, 0])], [array([1, 1, 1, 1, 4])], [array([1, 8, 1, 1, 1])], [array([1, 1, 1, 0, 1])], [array([1, 1, 1, 1])]]\n",
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]]\n",
      "Val accuracy 5:\n",
      "Epoch 6/10 - Train loss: 0.520539449571177, Validation loss: 1.4449308812618256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfbe5879ed9413ba471f42e878bfa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ede0a5afae744e689472e5547e7ce18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "End validation for epoch 6\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 6\n",
      "Count of iterations: 9 for epoch 6\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "[[1 1 1 1 1]\n",
      " [0 1 1 0 0]]\n",
      "Val accuracy 6:\n",
      "Epoch 7/10 - Train loss: 0.44941495341617005, Validation loss: 0.47519492798230867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbb7870e8ac4eefa4c2c1c16dbf9b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bc43434a364b8b850a7832badb5a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "[array([0, 0, 1, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 1])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 1, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])], [array([0, 0, 0, 1, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.\n",
      "[array([1, 0, 0, 0, 1])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])], [array([0, 0, 0, 1, 0])], [array([1, 0, 0, 0, 1])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])], [array([0, 0, 0, 1, 0])], [array([1, 0, 0, 0, 1])], [array([0, 0, 0, 0, 0])]]\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0])]\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])], [array([0, 0, 0, 1, 0])], [array([1, 0, 0, 0, 1])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "End validation for epoch 7\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x7a85b974d810>\n",
      "Label predict shape : 9 for epoch 7\n",
      "Count of iterations: 9 for epoch 7\n",
      "Concatenation error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "[array([0, 0, 0, 0, 0]), [array([0, 0, 1, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0, 1])], [array([0, 0, 0, 1, 0])], [array([1, 0, 0, 0, 1])], [array([0, 0, 0, 0, 0])], [array([0, 0, 0, 0])]]\n",
      "[[0 0 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Val accuracy 7:\n",
      "Epoch 8/10 - Train loss: 0.5589388755345067, Validation loss: 0.4823868769136342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2645ca1f1fa647f1b03f197f59195a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m salvar_model(model, path=\u001b[33m'\u001b[39m\u001b[33moutput/modelos\u001b[39m\u001b[33m'\u001b[39m, name_file=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTrain and valid for Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m t, l,_,outputs,labels = \u001b[43msimple_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m## Evaluate model.\u001b[39;00m\n\u001b[32m     22\u001b[39m salvar_metricas(path=\u001b[33m'\u001b[39m\u001b[33moutput/metricas\u001b[39m\u001b[33m'\u001b[39m, name_file_train=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpredict_label_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m, name_file_val=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrue_label_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m, predict_label= outputs, true_label= labels)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36msimple_loop\u001b[39m\u001b[34m(model, train_image, val_image, epochs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#print(label)\u001b[39;00m\n\u001b[32m     33\u001b[39m loss_train = criterion(outputs.float(), label.float())\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mloss_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m optimizer.step()\n\u001b[32m     36\u001b[39m running_loss_train += loss_train.item() * label.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/oca-ia/.venv/lib/python3.13/site-packages/torch/_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/oca-ia/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/oca-ia/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_total = []\n",
    "val_loss_total =[]\n",
    "all_models =[]\n",
    "epochs = 10\n",
    "## create first model.\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    #print(f\"  Train: index={train_index}\")\n",
    "    #print(f\"  Test:  index={test_index}\")\n",
    "    ## init train test for folder\n",
    "    train_dataset_part = Subset( train_dataset, train_index)\n",
    "    val_dataset_part = Subset( train_dataset, test_index)\n",
    "\n",
    "    train_loader_img = DataLoader(train_dataset_part, batch_size=5, shuffle=True)\n",
    "    val_loader_img = DataLoader(val_dataset_part, batch_size=5, shuffle=True)\n",
    "\n",
    "    model= ECGClassifierResnet( num_classes=1)\n",
    "    salvar_model(model, path='output/modelos', name_file=f'model_fold_{i}.pth')\n",
    "    print(f'Train and valid for Fold {i}')\n",
    "    t, l,_,outputs,labels = simple_loop(model, train_loader_img,val_loader_img, epochs)\n",
    "    ## Evaluate model.\n",
    "    salvar_metricas(path='output/metricas', name_file_train=f'predict_label_{i}.npy', name_file_val=f'true_label_{i}.npy', predict_label= outputs, true_label= labels)\n",
    "    train_loss_total.append(t)\n",
    "    val_loss_total.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616],\n",
       "        [31616, 31616, 31616, 31616, 31616]],\n",
       "\n",
       "       [[   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17],\n",
       "        [   17,    17,    17,    17,    17]],\n",
       "\n",
       "       [[    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2],\n",
       "        [    2,     2,     2,     2,     2]],\n",
       "\n",
       "       [[    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0]],\n",
       "\n",
       "       [[    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs\n",
    "## formato ddos outputs [epoch][batch][labels]\n",
    "#out = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38154859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels[0][0:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f4f10",
   "metadata": {},
   "source": [
    "## Métricas de Avaliacao dos modelos\n",
    "\n",
    "Acuracia\n",
    "\n",
    "Precisao\n",
    "\n",
    "Sensibilidade\n",
    "\n",
    "Especificidade\n",
    "\n",
    "F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Leitura de métricas salvas\n",
    "import numpy as np\n",
    "predict_label_0 = np.load('output/metricas/predict_label_0.npy')\n",
    "true_label_0 = np.load('output/metricas/true_label_0.npy')\n",
    "# --- IGNORE ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5090, 4552, 5090, 5090, 5090],\n",
       "        [9356, 5090, 3771, 5021, 5090],\n",
       "        [5090, 5090, 3520, 5090, 5453],\n",
       "        [5090, 5090, 5090, 9419, 5090],\n",
       "        [5090, 5090, 5090, 5090, 4520],\n",
       "        [5090, 5090, 4277, 5090, 5090],\n",
       "        [3335, 5090, 7920, 5090, 5090],\n",
       "        [5090, 5090, 5017, 5281, 5090]],\n",
       "\n",
       "       [[   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0]],\n",
       "\n",
       "       [[  31,   31,    1,    3,   31],\n",
       "        [  31,   31,   31,    1,   31],\n",
       "        [  31,   31,    4,   31,   31],\n",
       "        [  31,   31,    2,   31,   31],\n",
       "        [  20,   31,   31,    0,   31],\n",
       "        [  77,   11,   31,   31,   31],\n",
       "        [  31,    4,   31,    1,   31],\n",
       "        [   2,   31,   39,    9,   31]],\n",
       "\n",
       "       [[   0,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    0,    1],\n",
       "        [   1,    1,    1,    1,    1],\n",
       "        [   0,    0,    0,    0,    1],\n",
       "        [   1,    1,    0,    1,    1],\n",
       "        [   1,    0,    1,    3,    1],\n",
       "        [   1,    1,    0,    0,    0],\n",
       "        [  13,    1,    0,    0,    1]],\n",
       "\n",
       "       [[   1,    1,    1,    0,    1],\n",
       "        [   1,    1,    0,    1,    0],\n",
       "        [   1,    1,    0,    1,    0],\n",
       "        [   1,    1,    0,    0,    1],\n",
       "        [   0,    1,    1,    1,    1],\n",
       "        [   1,    1,    0,    1,    1],\n",
       "        [   0,    1,    1,    1,    0],\n",
       "        [   0,    1,    0,    1,    1]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.75"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "220/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9399a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102, 5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"a\")\n",
    "print(type(predict_label_0))\n",
    "predict_label_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc67921",
   "metadata": {},
   "source": [
    "## Criacao graficos de treinamento e validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criar graficos de treinamento e validacao\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_loss_total[i], label='Train Loss')\n",
    "    plt.plot(val_loss_total[i], label='Validation Loss')\n",
    "    plt.title(f'Fold {i} - Train and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'output/graficos/loss_fold_{i}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdd0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

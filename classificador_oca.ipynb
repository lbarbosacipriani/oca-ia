{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb18702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (11.3.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.3.2)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: timm in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.0.20)\n",
      "Requirement already satisfied: jupyter_contrib_nbextensions in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: widgetsnbextension in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (4.0.14)\n",
      "Collecting pandas-profiling (from -r requirements.txt (line 10))\n",
      "  Using cached pandas_profiling-3.2.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (3.10.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2025.9.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.23.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.35.3)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.6.2)\n",
      "Requirement already satisfied: ipython_genutils in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: jupyter_contrib_core>=0.3.3 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: jupyter_core in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (5.8.1)\n",
      "Requirement already satisfied: jupyter_highlight_selected_word>=0.1.1 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: jupyter_nbextensions_configurator>=0.4.0 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (0.6.4)\n",
      "Requirement already satisfied: nbconvert>=6.0 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (7.16.6)\n",
      "Requirement already satisfied: notebook>=6.0 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (7.4.7)\n",
      "Requirement already satisfied: tornado in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=4.1 in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.13/site-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (9.5.0)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (3.0.15)\n",
      "INFO: pip is looking at multiple versions of pandas-profiling to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pandas_profiling-3.1.0-py2.py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached pandas_profiling-3.0.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pydantic>=1.8.1 (from pandas-profiling->-r requirements.txt (line 10))\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting visions==0.7.1 (from visions[type_image_path]==0.7.1->pandas-profiling->-r requirements.txt (line 10))\n",
      "  Using cached visions-0.7.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting htmlmin>=0.1.12 (from pandas-profiling->-r requirements.txt (line 10))\n",
      "  Using cached htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/leonardocipriani/Documents/dev/python/Artificial Intelligence Projects/oca-ia/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/leonardocipriani/Documents/dev/python/Artificial Intelligence Projects/oca-ia/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/leonardocipriani/Documents/dev/python/Artificial Intelligence Projects/oca-ia/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-build-env-mipzxpmt/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-build-env-mipzxpmt/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-build-env-mipzxpmt/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-build-env-mipzxpmt/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m4\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-install-i_avnif5/htmlmin_9bf659dcdc6d419e99e8b3c1cd71e009/htmlmin/__init__.py\"\u001b[0m, line \u001b[35m28\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     from .main import minify, Minifier\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/pip-install-i_avnif5/htmlmin_9bf659dcdc6d419e99e8b3c1cd71e009/htmlmin/main.py\"\u001b[0m, line \u001b[35m28\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     import cgi\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'cgi'\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22170478",
   "metadata": {},
   "source": [
    "## Exemplo de classificador com leitura do CSV. \n",
    "\n",
    "Etapas:\n",
    "\n",
    "- Leitura CSV.\n",
    "- Tratamento de imagens com lib PIL. \n",
    "- Leitura imagem. \n",
    "- Aplicacao Filtro para remocao background\n",
    "\n",
    "\n",
    "Input do modelo : (Imagem, sexo, idade, etnia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de731cfa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ca2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.ImageFIlter import treat_image_PIL\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import  DataLoader, TensorDataset, Dataset\n",
    "from torch import nn\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd08e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geracao dataset com aleatorio\n",
    "ds_file = pd.read_csv('dataset/exemplo_csv_2.csv')\n",
    "arr = np.random.choice([0, 1], size=216)\n",
    "\n",
    "ds_file = ds_file[['path','image_id','ID','IDADE','SEXO','ETNIA']]\n",
    "ds_file['oca'] = arr\n",
    "ds_file.to_csv('dataset/oca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c59064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file = pd.read_csv('dataset/oca.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52323b9c",
   "metadata": {},
   "source": [
    "## Geracao Tensor com imagens filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eaf296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop\n",
    "img_dataset = np.ones((ds_file.shape[0],3,256,256),dtype=np.uint8)\n",
    "\n",
    "j=0\n",
    "for i in ds_file['path']:\n",
    "    img_dataset[j]=treat_image_PIL('dataset/path/'+i,2)\n",
    "    j+=1\n",
    "tensor_imagem = torch.tensor(img_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c242f0e",
   "metadata": {},
   "source": [
    "## Geracao Tensor Age, sex, Etinia\n",
    "\n",
    "Encoding: \n",
    "\n",
    "- Sexo: M=0 F=1\n",
    "\n",
    "- Idade: Normalizar? Sim, dividir por 100 igual o artigo do Marco e Felipe fizeram. \n",
    "\n",
    "- Etnia: Encoding simples de categorias. Utilizaremos o Label Encoding para isso "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aec203",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b39994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/ipykernel_52174/1074131203.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_id_sex_et['SEXO'] = ds_file['SEXO'].map({ 'M':0, 'F':1})\n",
      "/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/ipykernel_52174/1074131203.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_id_sex_et['IDADE'] = ds_file['IDADE']/100\n"
     ]
    }
   ],
   "source": [
    "ds_id_sex_et= ds_file[['IDADE', 'SEXO', 'ETNIA']]\n",
    "ds_id_sex_et['SEXO'] = ds_file['SEXO'].map({ 'M':0, 'F':1})\n",
    "ds_id_sex_et['IDADE'] = ds_file['IDADE']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc21ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/pgp77_r92w5_rn1ghx4kn51h0000gn/T/ipykernel_52174/2772605160.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_id_sex_et['ETNIA'] = le.fit_transform(ds_id_sex_et['ETNIA'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>ETNIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IDADE  SEXO  ETNIA\n",
       "0     0.85     0      1\n",
       "1     0.32     1      1\n",
       "2     0.60     1      1\n",
       "3     0.57     1      4\n",
       "4     0.57     1      1\n",
       "..     ...   ...    ...\n",
       "211   0.35     1      3\n",
       "212   0.72     0      2\n",
       "213   0.71     1      2\n",
       "214   0.49     0      2\n",
       "215   0.19     1      3\n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encoding variavel ETNIA -> Usando label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a sample dataframe with categorical data\n",
    "\n",
    "#print(f\"Before Encoding the Data:\\n\\n{ds_id_sex_et['ETNIA']}\\n\")\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "ds_id_sex_et['ETNIA'] = le.fit_transform(ds_id_sex_et['ETNIA'])\n",
    "ds_id_sex_et"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dbdca",
   "metadata": {},
   "source": [
    "## Geracao de rótulos para classificação\n",
    "\n",
    "Colunas utilizadas para classificacao (Labels)\n",
    "\n",
    "labels = [ OCA, NOCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bd06990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "ds_file.columns\n",
    "labels = [ 'oca']\n",
    "ds_labels = ds_file[labels]\n",
    "ds_labels=ds_labels.astype(int)#,'False':0})\n",
    "tensor_label = torch.tensor(np.array(ds_labels))\n",
    "tensor_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9fcbf",
   "metadata": {},
   "source": [
    "### Resumo:\n",
    "\n",
    "model(tensor_imagem,ds_id_sex_et)\n",
    "\n",
    "labels : tensor_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc188221",
   "metadata": {},
   "source": [
    "## Criacao Subset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fdd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subset(Dataset):\n",
    "    r\"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): The whole Dataset\n",
    "        indices (sequence): Indices in the whole set selected for subset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead13f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f0dcb69",
   "metadata": {},
   "source": [
    "## K-fold = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e96965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(tensor_imagem)\n",
    "print(kf)\n",
    "#for i in enumerate(kf.split(tensor_imagem)):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64652bf",
   "metadata": {},
   "source": [
    "## Criacao do dataset de treino e validacao com batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "925d5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataset = TensorDataset(tensor_imagem, tensor_label)\n",
    "train_loader_img = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d682980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba835adf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addfb539",
   "metadata": {},
   "source": [
    "## Create a model to concat layers\n",
    "\n",
    "O modelo utilizado será o mesmo do artigo: Artificial Intelligence-Driven Screening System for Rapid Image-Based Classification of 12-Lead ECG Exams: A Promising Solution for Emergency Room Prioritization \n",
    "\n",
    "Desenvolvido conforme a figura abaixo: \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32068ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import ECGClassifierResnet\n",
    "\n",
    "class ECGClassifierResnet(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ECGClassifierResnet, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        #self.base_model = timm.create_model('efficientnet_b0', pretrained=True) \n",
    "        self.base_model=timm.create_model('resnet50d.ra4_e3600_r224_in1k',pretrained=True)\n",
    "        #self.base_model = timm.create_model('vit_mediumd_patch16_reg4_gap_256.sbb2_e200_in12k_ft_in1k',num_classes=5,pretrained=True)\n",
    "\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "\n",
    "        enet_out_size = 2048        # Make a classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(enet_out_size,1)\n",
    "        ) # saida como Sigmoid multilabel\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198fcb9",
   "metadata": {},
   "source": [
    "## Train - Valid Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cda9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \" + str(device))\n",
    "def simple_loop(model, train_image, val_image, epochs):\n",
    "    # Simple training loop\n",
    "    num_epochs = epochs\n",
    "    train_losses, val_losses = [], []\n",
    "    lim_loss = 1.5\n",
    "\n",
    "    #model = modelo( num_classes=5)\n",
    "    model.to(device)\n",
    "    #criterion =  nn.BCEWithLogitsLoss()\n",
    "    criterion =  nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    predict_label_full = np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "    true_label_full = np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        for images, labels in tqdm(train_image, desc='Training loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images = images.to(torch.float)\n",
    "            image, label = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image)\n",
    "            loss_train = criterion(outputs.float(), label.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss_train.item() * label.size(0)\n",
    "        train_loss = running_loss_train / len(train_image.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        running_loss_valid = 0.0\n",
    "        rotulos =[] \n",
    "        predict_label =np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "        true_label =np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_image, desc='Validation loop'):\n",
    "                # Move inputs and labels to the device\n",
    "                images = images.to(torch.float)\n",
    "                images, label = images.to(device), labels.to(device)\n",
    "                rotulos.append(label.cpu().data.numpy())\n",
    "                outputs = model(images)\n",
    "                loss_valid = criterion(outputs.float(), label.float())\n",
    "                #print( [outputs.cpu().data.numpy().astype(int).T[0]])\n",
    "                #print(label.cpu().data.numpy().astype(int).T[0])\n",
    "                #print(predict_label)\n",
    "                try:\n",
    "                    _pred = [outputs.cpu().data.numpy().astype(int).T[0]]\n",
    "                    print(_pred)\n",
    "                    predict_label=np.concatenate((predict_label,_pred), axis=0)\n",
    "                    print(predict_label)\n",
    "                    _true = [label.cpu().data.numpy().astype(int).T[0]]\n",
    "                    true_label=np.concatenate((true_label, _true), axis=0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Concatenation error: {e}\")\n",
    "                    print(_pred)\n",
    "                    print(predict_label)    \n",
    "                running_loss_valid += loss_valid.item() * label.size(0)\n",
    "        val_loss = running_loss_valid / len(val_image.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        try:\n",
    "            predict_label_full=np.concatenate((predict_label_full,[predict_label]), axis=0)\n",
    "            true_label_full=np.concatenate((true_label_full,[true_label]), axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Concatenation error: {e}\")\n",
    "            print(predict_label)\n",
    "            print(true_label)\n",
    "        #val_acc = accuracy_score(rotulos,output_model)\n",
    "        print(f'Val accuracy {1}')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "    \n",
    "    return train_losses, val_losses, model,predict_label_full, true_label_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0808206c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,1,1,1,1],[1,1,1,1,1]], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "27f05aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5],[1,2,3,4,5]], dtype=int)\n",
    "b = np.array([6,7,8,9,10], dtype=int)\n",
    "print(a)\n",
    "c = np.concatenate((a,[b]), axis=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "c6859637",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() missing 1 required positional argument: 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[318]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m predict_label1 =np.empty([\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m], dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m      5\u001b[39m a = np.zeros((\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m predict_label =\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredict_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m predict_label\n",
      "\u001b[31mTypeError\u001b[39m: append() missing 1 required positional argument: 'values'"
     ]
    }
   ],
   "source": [
    "predict_label =np.empty([2,2])\n",
    "true_label =np.array([])\n",
    "predict_label1 =np.empty([2,2], dtype=float)\n",
    "\n",
    "a = np.zeros((2,2))\n",
    "predict_label =np.append([predict_label, a])\n",
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5800f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.ones([5], dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "809e6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_model(model, path = 'output/modelos', name_file='model.pth'):\n",
    "    full_path = os.path.join(path, name_file)\n",
    "    torch.save(model.state_dict(), full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "60622c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_metricas(path='output/metricas', name_file_train='train_loss_total.npy', name_file_val='val_loss_total.npy',predict_label=None, true_label=None):\n",
    "    full_path_train = os.path.join(path, name_file_train)\n",
    "    full_path_val = os.path.join(path, name_file_val)\n",
    "    np.save(full_path_train, np.array(predict_label))\n",
    "    np.save(full_path_val, np.array(true_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4df8a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train and valid for Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcac339ab0d540138824cdfaa85c5df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ae1a1c9bb48028168a3ee014223f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0])]\n",
      "Concatenation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 4\n",
      "[array([0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 1]]\n",
      "Concatenation error: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 1]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Val accuracy 1\n",
      "Epoch 1/1 - Train loss: 0.0, Validation loss: 0.0\n",
      "Fold 1:\n",
      "Train and valid for Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b2e2e0176b4a9eb86b4cd18de5e11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd41ab08238f49a9a1b964a964e869c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 1]\n",
      " [1 1 0 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 1]\n",
      " [1 1 0 0 0]\n",
      " [1 0 0 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0])]\n",
      "Concatenation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 3\n",
      "[array([0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 1]\n",
      " [1 1 0 0 0]\n",
      " [1 0 0 0 1]]\n",
      "Concatenation error: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 1]\n",
      " [1 1 0 0 0]\n",
      " [1 0 0 0 1]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Val accuracy 1\n",
      "Epoch 1/1 - Train loss: 0.0, Validation loss: 0.0\n",
      "Fold 2:\n",
      "Train and valid for Fold 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401b2b2cddf040edb04f6199550d5c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690f7b165e434a06a332e93ff4510533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [0 1 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 0 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 0 1 0]\n",
      " [1 1 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0])]\n",
      "Concatenation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 3\n",
      "[array([0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 0 1 0]\n",
      " [1 1 1 0 0]]\n",
      "Concatenation error: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 0 1 0]\n",
      " [1 1 1 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Val accuracy 1\n",
      "Epoch 1/1 - Train loss: 0.0, Validation loss: 0.0\n",
      "Fold 3:\n",
      "Train and valid for Fold 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caddad40167434cb7989a0b86a887d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75556775e5b140b7993331c144bdee2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0])]\n",
      "Concatenation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 3\n",
      "[array([0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 1 1 1]]\n",
      "Concatenation error: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 1 1 1]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Val accuracy 1\n",
      "Epoch 1/1 - Train loss: 0.0, Validation loss: 0.0\n",
      "Fold 4:\n",
      "Train and valid for Fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f700fca6804b37ba4dc587877b539f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0f8fb521aa4f0c8bff7e6ddfa51f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 1 1]\n",
      " [1 0 1 0 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 1 1]\n",
      " [1 0 1 0 1]\n",
      " [1 0 0 1 1]]\n",
      "Pred label\n",
      "[array([0, 0, 0])]\n",
      "Concatenation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 3\n",
      "[array([0, 0, 0])]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 1 1]\n",
      " [1 0 1 0 1]\n",
      " [1 0 0 1 1]]\n",
      "Concatenation error: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 1 1]\n",
      " [1 0 1 0 1]\n",
      " [1 0 0 1 1]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Val accuracy 1\n",
      "Epoch 1/1 - Train loss: 0.0, Validation loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_total = []\n",
    "val_loss_total =[]\n",
    "all_models =[]\n",
    "epochs = 1\n",
    "## create first model.\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    #print(f\"  Train: index={train_index}\")\n",
    "    #print(f\"  Test:  index={test_index}\")\n",
    "    ## init train test for folder\n",
    "    train_dataset_part = Subset( train_dataset, train_index)\n",
    "    val_dataset_part = Subset( train_dataset, test_index)\n",
    "\n",
    "    train_loader_img = DataLoader(train_dataset_part, batch_size=5, shuffle=True)\n",
    "    val_loader_img = DataLoader(val_dataset_part, batch_size=5, shuffle=True)\n",
    "\n",
    "    model= ECGClassifierResnet( num_classes=1)\n",
    "    salvar_model(model, path='output/modelos', name_file=f'model_fold_{i}.pth')\n",
    "    print(f'Train and valid for Fold {i}')\n",
    "    t, l,_,outputs,labels = simple_loop(model, train_loader_img,val_loader_img, epochs)\n",
    "    ## Evaluate model.\n",
    "    salvar_metricas(path='output/metricas', name_file_train=f'predict_label_{i}.npy', name_file_val=f'true_label_{i}.npy', predict_label= outputs, true_label= labels)\n",
    "    train_loss_total.append(t)\n",
    "    val_loss_total.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "38154859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1, 22180, 21973, 22180, 17202, 29978, 22180, 22180, 22180,\n",
       "       38713, 22571, 31117, 38375, 22180, 17712, 26842, 22180, 22180,\n",
       "       22180, 22180, 22180, 26452, 22180, 22180, 22180, 22180, 22180,\n",
       "       35583, 16483, 22180, 22180, 22180, 22180, 22180, 22180, 22180,\n",
       "       22180, 22180, 22180, 29720, 22180, 22180, 32061, 26868, 22180])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f4f10",
   "metadata": {},
   "source": [
    "## Métricas de Avaliacao dos modelos\n",
    "\n",
    "Acuracia\n",
    "\n",
    "Precisao\n",
    "\n",
    "Sensibilidade\n",
    "\n",
    "Especificidade\n",
    "\n",
    "F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "70a0dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Leitura de métricas salvas\n",
    "import numpy as np\n",
    "predict_label_0 = np.load('output/metricas/predict_label_0.npy')\n",
    "true_label_0 = np.load('output/metricas/true_label_0.npy')\n",
    "# --- IGNORE ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1251295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd73f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.75"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "220/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed9399a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(220,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"a\")\n",
    "print(type(predict_label_0))\n",
    "predict_label_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc67921",
   "metadata": {},
   "source": [
    "## Criacao graficos de treinamento e validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criar graficos de treinamento e validacao\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_loss_total[i], label='Train Loss')\n",
    "    plt.plot(val_loss_total[i], label='Validation Loss')\n",
    "    plt.title(f'Fold {i} - Train and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'output/graficos/loss_fold_{i}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdd0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beb18702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (12.1.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.4.2)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: timm in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.0.24)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (8.1.8)\n",
      "Requirement already satisfied: widgetsnbextension in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (4.0.15)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (3.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (80.10.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2026.1.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in ./.venv/lib/python3.13/site-packages (from cuda-bindings==12.9.4->torch->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.25.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (1.3.5)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.13/site-packages (from timm->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 7)) (3.0.16)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (26.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (4.67.2)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (0.21.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface_hub->timm->-r requirements.txt (line 6)) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b40d20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.ImageFIlter import treat_image_PIL\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import  DataLoader, TensorDataset, Dataset\n",
    "from torch import nn\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de731cfa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0662af5c",
   "metadata": {},
   "source": [
    "## Funcao de filtro de imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d25891a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import io\n",
    "from pathlib import Path\n",
    "path = '/home/leo/Documents/ecg_classifier/dataset/database_ptbxl/'\n",
    "def treat_image_PIL(img_path, type_return=2):\n",
    "    ''''\n",
    "    Input: Img_path, type return.\n",
    "\n",
    "    Img_path: path da imagem em formato png, img...\n",
    "    type_return: 1-> retorno como PIL. \n",
    "                2 ou sem type_return -> retorno como numpy array tipo uint8\n",
    "\n",
    "    Output:\n",
    "    '''\n",
    "    im = Image.open(path+img_path) \n",
    "    \n",
    "    # Size of the image in pixels (size of original image) \n",
    "    # (This is not mandatory) \n",
    "    width, height = im.size \n",
    "\n",
    "    rgb =Image.Image.split(im) \n",
    "\n",
    "    data =rgb\n",
    "    b= data[0]\n",
    "    g= data[1]\n",
    "    r= data[2]\n",
    "    #img_out = b+g+.5*r\n",
    "    #img_out_2 = img_out[500:1600, 50:2100] \n",
    "\n",
    "    newsize = (256, 256)\n",
    "   # im3 =ImageChops.subtract(mask,b, scale=1.0, offset=0)\n",
    "\n",
    "    b1 = b.crop((120,500,2100,1600))\n",
    "    g1 = g.crop((120,500,2100,1600))\n",
    "    r1 = r.crop((120,500,2100,1600))\n",
    "    im1 = b1.resize(newsize, Image.Resampling.LANCZOS).convert('L')\n",
    "    im2 = g1.resize(newsize, Image.Resampling.LANCZOS).convert('L')\n",
    "    im3 = r1.resize(newsize, Image.Resampling.LANCZOS).convert('L')\n",
    "    if type_return ==1:\n",
    "        return im1 \n",
    "    else:\n",
    "        return np.array([im1,im2,im3],dtype=np.uint8)\n",
    "\n",
    "\n",
    "def save_file_to_dir(file_obj, directory, filename):\n",
    "    \"\"\"\n",
    "    Save a file to `directory` with the given `filename`.\n",
    "\n",
    "    Parameters\n",
    "    - file_obj: a PIL Image, a filesystem path (str or Path) to an existing file,\n",
    "                bytes/bytearray, or a file-like object with a .read() method.\n",
    "    - directory: target directory where the file will be saved.\n",
    "    - filename: the name to use for the saved file (including extension if desired).\n",
    "\n",
    "    Returns\n",
    "    - full path (str) to the saved file.\n",
    "\n",
    "    Raises\n",
    "    - FileNotFoundError if a provided source path does not exist.\n",
    "    - ValueError if the provided file_obj type is unsupported.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    dest = os.path.join(directory, filename)\n",
    "\n",
    "    # PIL Image\n",
    "    if isinstance(file_obj, Image.Image):\n",
    "        file_obj.save(dest)\n",
    "        return dest\n",
    "\n",
    "    # Path-like or string pointing to an existing file\n",
    "    if isinstance(file_obj, (str, Path)):\n",
    "        src = str(file_obj)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy(src, dest)\n",
    "            return dest\n",
    "        raise FileNotFoundError(f\"Source path not found: {src}\")\n",
    "\n",
    "    # File-like object\n",
    "    if hasattr(file_obj, \"read\"):\n",
    "        data = file_obj.read()\n",
    "        # If read() returned bytes -> try open as image, otherwise write raw\n",
    "        if isinstance(data, (bytes, bytearray)):\n",
    "            try:\n",
    "                img = Image.open(io.BytesIO(data))\n",
    "                img.save(dest)\n",
    "                return dest\n",
    "            except Exception:\n",
    "                with open(dest, \"wb\") as f:\n",
    "                    f.write(data)\n",
    "                return dest\n",
    "        else:\n",
    "            # assume text\n",
    "            with open(dest, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(data)\n",
    "            return dest\n",
    "\n",
    "    # Raw bytes\n",
    "    if isinstance(file_obj, (bytes, bytearray)):\n",
    "        try:\n",
    "            img = Image.open(io.BytesIO(file_obj))\n",
    "            img.save(dest)\n",
    "            return dest\n",
    "        except Exception:\n",
    "            with open(dest, \"wb\") as f:\n",
    "                f.write(file_obj)\n",
    "            return dest\n",
    "\n",
    "    raise ValueError(\"file_obj must be a PIL.Image, path string/Path, bytes or file-like object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d7ce4",
   "metadata": {},
   "source": [
    "## Funcoes output_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44fde85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## Cria funcao para validar se pasta a ser inserida existe. Caso nao exista, cria a pasta\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f'Pasta {folder_path} criada.')\n",
    "    else:\n",
    "        print(f'Pasta {folder_path} ja existe.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63dfac",
   "metadata": {},
   "source": [
    "## Funcoes subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3057848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  Dataset\n",
    "\n",
    "class Subset(Dataset):\n",
    "    r\"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): The whole Dataset\n",
    "        indices (sequence): Indices in the whole set selected for subset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes\n",
    "\n",
    "    def shape(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a35fdff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f255a4",
   "metadata": {},
   "source": [
    "## Funcoes simple_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9688a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \" + str(device))\n",
    "\n",
    "def salvar_model(model, path = 'output/modelos', name_file='model.pth'):\n",
    "    create_folder_if_not_exists(path)\n",
    "\n",
    "    full_path = os.path.join(path, name_file)\n",
    "    torch.save(model.state_dict(), full_path)\n",
    "\n",
    "def salvar_metricas(path, name_file_train='train_loss_total.npy', name_file_val='val_loss_total.npy',predict_label=None, true_label=None):\n",
    "    create_folder_if_not_exists(path)\n",
    "    full_path_train = os.path.join(path, name_file_train)\n",
    "    full_path_val = os.path.join(path, name_file_val)\n",
    "    np.save(full_path_train, np.array(predict_label))\n",
    "    np.save(full_path_val, np.array(true_label))\n",
    "    print(f'Metricas salvas em {path} com os nomes {name_file_train} e {name_file_val} e tamanhos {np.array(predict_label).shape} e {np.array(true_label).shape}')\n",
    "\n",
    "def simple_loop(model, train_image, val_image, epochs, batch_size, fold_index):\n",
    "    # Simple training loop\n",
    "    num_epochs = epochs\n",
    "    train_losses, val_losses = [], []\n",
    "    lim_loss = 1.5\n",
    "    iter_size = batch_size\n",
    "    print(f'Number of training images per iteration: {iter_size}')\n",
    "    #model = modelo( num_classes=5)\n",
    "  # model.to(device)\n",
    "    #criterion =  nn.NLLLoss()\n",
    "    criterion =  nn.BCEWithLogitsLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    predict_label_full_train = []\n",
    "    predict_label_full = []\n",
    "    true_label_full_train = []\n",
    "    true_label_full = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        predict_label_train =[]\n",
    "        true_label_train =[]\n",
    "        running_loss_train = 0.0\n",
    "        for images, labels in tqdm(train_image, desc='Training loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images = images.to(torch.float)\n",
    "            image, label = images, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image)\n",
    "            #loss_train = criterion(outputs.float(), label.float())\n",
    "            loss_train = criterion(outputs, label)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss_train.item() * label.size(0)\n",
    "            try:\n",
    "                _pred_train = outputs.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "                if(len(_pred_train) == iter_size):\n",
    "                    predict_label_train.append(_pred_train)\n",
    "                    _true_train = label.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "                    true_label_train.append(_true_train)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Concatenation error iter: {e}\")\n",
    "                print(_pred_train)\n",
    "                print(predict_label_train)    \n",
    "        train_loss = running_loss_train / len(train_image.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        try:\n",
    "            _p_train = predict_label_train\n",
    "            _t_train = true_label_train\n",
    "            predict_label_full_train.append(_p_train)\n",
    "            true_label_full_train.append(_t_train)\n",
    "        except Exception as e:\n",
    "            print(f\"Concatenation error full: {e}\")\n",
    "            print(predict_label_train)\n",
    "            print(true_label_train)\n",
    "        model.eval()\n",
    "        running_loss_valid = 0.0\n",
    "        rotulos =[] \n",
    "        predict_label =[]\n",
    "        true_label =[]\n",
    "        _iter=0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_image, desc='Validation loop'):\n",
    "                # Move inputs and labels to the device\n",
    "                images = images.to(torch.float)\n",
    "                images, label = images, labels\n",
    "                rotulos.append(label.cpu().data.numpy())\n",
    "                outputs = model(images)\n",
    "                #loss_valid = criterion(outputs.float(), label.float())\n",
    "                loss_valid = criterion(outputs, label)\n",
    "\n",
    "                #print( [outputs.cpu().data.numpy().astype(int).T[0]])\n",
    "                #print(label.cpu().data.numpy().astype(int).T[0])\n",
    "                #print(predict_label)\n",
    "                try:\n",
    "                    _pred = outputs.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "\n",
    "                    if(len(_pred) == iter_size):\n",
    "                        predict_label.append(_pred)\n",
    "                        _true = label.cpu().data.numpy().astype(int).T[0].tolist()\n",
    "                        true_label.append(_true)\n",
    "                except Exception as e:\n",
    "                    print(f\"Concatenation error iter: {e}\")\n",
    "                    print(_pred)\n",
    "                    print(predict_label)    \n",
    "                running_loss_valid += loss_valid.item() * label.size(0)\n",
    "                _iter +=1\n",
    "        val_loss = running_loss_valid / len(val_image.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'End validation for epoch {epoch}')\n",
    "        print(f'Amount of images validated: {val_image}')\n",
    "        print(f'Label predict shape : {len(predict_label)} for epoch {epoch}')\n",
    "        print(f'Count of iterations: {_iter} for epoch {epoch}')\n",
    "        try:\n",
    "            _p = predict_label\n",
    "            _t = true_label\n",
    "            predict_label_full.append(_p)\n",
    "            true_label_full.append(_t)\n",
    "        except Exception as e:\n",
    "            print(f\"Concatenation error full: {e}\")\n",
    "            print(predict_label)\n",
    "            print(true_label)\n",
    "        #val_acc = accuracy_score(rotulos,output_model)\n",
    "        print(f'Val accuracy {epoch}:')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "\n",
    "    predict_label_full_out = np.array(predict_label_full)\n",
    "    true_label_full_out = np.array(true_label_full)\n",
    "    predict_label_full_train_out = np.array(predict_label_full_train)\n",
    "    true_label_full_train_out = np.array(true_label_full_train)\n",
    "    print(f'Salvado das metricas de validacao e treino')\n",
    "    salvar_metricas(path=f'output/metricas/valid/fold_{fold_index}', name_file_train=f'predict_label_valid_fold_{fold_index}.npy', name_file_val=f'true_label_valid_fold_{fold_index}.npy', predict_label= predict_label_full_out, true_label= true_label_full_out)\n",
    "    salvar_metricas(path=f'output/metricas/train/fold_{fold_index}', name_file_train=f'predict_label_train_fold_{fold_index}.npy', name_file_val=f'true_label_train_fold_{fold_index}.npy', predict_label= predict_label_full_train_out, true_label= true_label_full_train_out)\n",
    "    print(f'Finalizado o salvamento das metricas')\n",
    "    return train_losses, val_losses, model,predict_label_full_out, true_label_full_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb6c0f",
   "metadata": {},
   "source": [
    "## Funcao Modelo ECG Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "155cbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import ECGClassifierResnet\n",
    "from torch import nn\n",
    "import timm\n",
    "class ECGClassifierResnet(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ECGClassifierResnet, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        #self.base_model = timm.create_model('efficientnet_b0', pretrained=True) \n",
    "        self.base_model=timm.create_model('resnet50d.ra4_e3600_r224_in1k',pretrained=True)\n",
    "        #self.base_model = timm.create_model('vit_mediumd_patch16_reg4_gap_256.sbb2_e200_in12k_ft_in1k',num_classes=5,pretrained=True)\n",
    "\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "\n",
    "        enet_out_size = 2048        # Make a classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(enet_out_size,1)\n",
    "        ) # saida como Sigmoid multilabel\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        #output = nn.Softmax(dim=1)(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1a7a3",
   "metadata": {},
   "source": [
    "## Arquivo Main.py - Orquestrador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd08e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o programa...\n",
      "Parametros de Execucao:\n",
      "  Numero de folds para K-Fold Cross Validation: 2\n",
      "  Tamanho do batch para treinamento: 5\n",
      "  Numero de epocas para treinamento: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FILE_PATH = 'norm_outros_dataset.csv'\n",
    "\n",
    "\n",
    "print(\"Iniciando o programa...\")\n",
    "print(\"Parametros de Execucao:\")\n",
    "folds = 2\n",
    "epochs = 5\n",
    "BATCH_SIZE = 5\n",
    "flg_salvar_modelos = True\n",
    "\n",
    "print(f\"  Numero de folds para K-Fold Cross Validation: {folds}\")\n",
    "\n",
    "print(f\"  Tamanho do batch para treinamento: {BATCH_SIZE}\")\n",
    "\n",
    "print(f\"  Numero de epocas para treinamento: {epochs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33797eae",
   "metadata": {},
   "source": [
    "### Geracao do tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10c59064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura dos dados no arquivo 'norm_outros_dataset.csv'...\n",
      "Dados lidos com sucesso. Tamnaho dos dados: (100, 2)\n",
      "Geracao Tensor de Imagens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [00:05<00:00, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de Imagens gerado com sucesso. Tamanho do Tensor: torch.Size([100, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Leitura dos dados no arquivo '{FILE_PATH}'...\")\n",
    "\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "data = data.sample(n=100)\n",
    "data.rename(columns={data.columns[0]:'path'}, inplace=True)\n",
    "data.rename(columns={data.columns[1]:'label'}, inplace=True)\n",
    "print(\"Dados lidos com sucesso. Tamnaho dos dados:\", data.shape)\n",
    "\n",
    "print(\"Geracao Tensor de Imagens...\")\n",
    "## Loop\n",
    "img_dataset = np.ones((data.shape[0],3,256,256),dtype=np.uint8)\n",
    "\n",
    "j=0\n",
    "for i in tqdm(data['path'], desc='Processing images'):\n",
    "    img_dataset[j]=treat_image_PIL(i,2)\n",
    "    j+=1\n",
    "tensor_imagem = torch.tensor(img_dataset)\n",
    "print(\"Tensor de Imagens gerado com sucesso. Tamanho do Tensor:\", tensor_imagem.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "648b005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = tensor_imagem[0][0]\n",
    "len(img1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dbdca",
   "metadata": {},
   "source": [
    "### Geracao de rótulos para classificação\n",
    "\n",
    "Colunas utilizadas para classificacao (Labels)\n",
    "\n",
    "labels = [ OCA, NOCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29f9adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de Rotulos sendo gerado...\n",
      "Tensor de Rotulos gerado com sucesso. Tamanho do Tensor: torch.Size([100, 1])\n",
      "Configuracao do K-Fold para 2 folds...\n",
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "K-Fold configurado com sucesso.\n",
      "Iniciando o treinamento com K-Fold Cross Validation...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tensor de Rotulos sendo gerado...\")\n",
    "\n",
    "\n",
    "tensor_label = torch.tensor(np.array(data['label'].astype(\"float32\"))).unsqueeze(1)\n",
    "print(\"Tensor de Rotulos gerado com sucesso. Tamanho do Tensor:\", tensor_label.shape)\n",
    "\n",
    "print(f\"Configuracao do K-Fold para {folds} folds...\")\n",
    "kf = KFold(n_splits=folds)\n",
    "kf.get_n_splits(tensor_imagem)\n",
    "print(kf)\n",
    "print(\"K-Fold configurado com sucesso.\")\n",
    "\n",
    "print(\"Iniciando o treinamento com K-Fold Cross Validation...\")\n",
    "\n",
    "train_loss_total = []\n",
    "val_loss_total =[]\n",
    "all_models =[]\n",
    "\n",
    "train_dataset = TensorDataset(tensor_imagem, tensor_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05132809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1\n",
    "!echo $CUDA_LAUNCH_BLOCKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "497bcad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198fcb9",
   "metadata": {},
   "source": [
    "## Train - Valid Loop\n",
    "\n",
    "Fluxo de treinamento\n",
    "\n",
    "Input: modelo, dataloader_train, dataloader_teste , epocas.\n",
    "- Para cada epoca\n",
    "\n",
    "    - treinamento:\n",
    "\n",
    "        - para cada batch (lote de imagens) no dataloader_train: (executo para todo o dataloader)\n",
    "            \n",
    "            leitura das imagens e rotulos. \n",
    "            \n",
    "            prediz o rotulo (outputs): rotulos preditos para o tamanho do batch (ex: para um batch de 10, o \n",
    "            output tem tamanho 10)\n",
    "            \n",
    "            calcula o Loss () \n",
    "            \n",
    "            aplica o backward -> Ajuste dos pesos nos neuronios de acordo com o valor de loss (w_{i})\n",
    "\n",
    "            otimizo o modelo com optimizer.step()\n",
    "\n",
    "    - validacao (avaliacao do desempenho para aquele conjunto de treinamento):\n",
    "        - para cada batch (lote de imagens) no dataloader_train: (executo para todo o dataloader)\n",
    "\n",
    "            leitura das imagens e rotulos.\n",
    "\n",
    "            prediz o rotulo (outputs): rotulos preditos para o tamanho do batch (ex: para um batch de 10, o \n",
    "            output tem tamanho 10)\n",
    "            \n",
    "            calcula o Loss ()\n",
    "\n",
    "\n",
    "    - Calculo de metricas de loss media de validacao.\n",
    "\n",
    "    - Calculo de metrica de loss media de treinamento. \n",
    "\n",
    "    - Print de metricas de desempenho para a epoca. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b98ad758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECGClassifierResnet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5d5e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ###############################################\n",
      "      Inicio do treinamento com K-Fold Cross Validation\n",
      "      ###############################################\n",
      "      \n",
      "Fold 0:\n",
      "Pasta output/modelos ja existe.\n",
      "Train and valid for Fold 0\n",
      "Number of training images per iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 0\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712e916bbe50>\n",
      "Label predict shape : 10 for epoch 0\n",
      "Count of iterations: 10 for epoch 0\n",
      "Val accuracy 0:\n",
      "Epoch 1/5 - Train loss: 0.6974550127983093, Validation loss: 0.7007173240184784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 1\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712e916bbe50>\n",
      "Label predict shape : 10 for epoch 1\n",
      "Count of iterations: 10 for epoch 1\n",
      "Val accuracy 1:\n",
      "Epoch 2/5 - Train loss: 0.6155978918075562, Validation loss: 0.6929766893386841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 2\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712e916bbe50>\n",
      "Label predict shape : 10 for epoch 2\n",
      "Count of iterations: 10 for epoch 2\n",
      "Val accuracy 2:\n",
      "Epoch 3/5 - Train loss: 0.47849999368190765, Validation loss: 0.6544595241546631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 3\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712e916bbe50>\n",
      "Label predict shape : 10 for epoch 3\n",
      "Count of iterations: 10 for epoch 3\n",
      "Val accuracy 3:\n",
      "Epoch 4/5 - Train loss: 0.31739679276943206, Validation loss: 0.6283004730939865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 4\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712e916bbe50>\n",
      "Label predict shape : 10 for epoch 4\n",
      "Count of iterations: 10 for epoch 4\n",
      "Val accuracy 4:\n",
      "Epoch 5/5 - Train loss: 0.20480156242847442, Validation loss: 0.638000163435936\n",
      "Salvado das metricas de validacao e treino\n",
      "Pasta output/metricas/valid/fold_0 ja existe.\n",
      "Metricas salvas em output/metricas/valid/fold_0 com os nomes predict_label_valid_fold_0.npy e true_label_valid_fold_0.npy e tamanhos (5, 10, 5) e (5, 10, 5)\n",
      "Pasta output/metricas/train/fold_0 ja existe.\n",
      "Metricas salvas em output/metricas/train/fold_0 com os nomes predict_label_train_fold_0.npy e true_label_train_fold_0.npy e tamanhos (5, 10, 5) e (5, 10, 5)\n",
      "Finalizado o salvamento das metricas\n",
      "Fold 1:\n",
      "Pasta output/modelos ja existe.\n",
      "Train and valid for Fold 1\n",
      "Number of training images per iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 0\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712d159a4850>\n",
      "Label predict shape : 10 for epoch 0\n",
      "Count of iterations: 10 for epoch 0\n",
      "Val accuracy 0:\n",
      "Epoch 1/5 - Train loss: 0.6853026330471039, Validation loss: 0.7069928467273712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 1\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712d159a4850>\n",
      "Label predict shape : 10 for epoch 1\n",
      "Count of iterations: 10 for epoch 1\n",
      "Val accuracy 1:\n",
      "Epoch 2/5 - Train loss: 0.5841261923313141, Validation loss: 0.6841833710670471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 2\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712d159a4850>\n",
      "Label predict shape : 10 for epoch 2\n",
      "Count of iterations: 10 for epoch 2\n",
      "Val accuracy 2:\n",
      "Epoch 3/5 - Train loss: 0.4862534821033478, Validation loss: 0.6150533705949783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 3\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712d159a4850>\n",
      "Label predict shape : 10 for epoch 3\n",
      "Count of iterations: 10 for epoch 3\n",
      "Val accuracy 3:\n",
      "Epoch 4/5 - Train loss: 0.31316857039928436, Validation loss: 0.5477774977684021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loop: 100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation for epoch 4\n",
      "Amount of images validated: <torch.utils.data.dataloader.DataLoader object at 0x712d159a4850>\n",
      "Label predict shape : 10 for epoch 4\n",
      "Count of iterations: 10 for epoch 4\n",
      "Val accuracy 4:\n",
      "Epoch 5/5 - Train loss: 0.17272244654595853, Validation loss: 0.6518205255270004\n",
      "Salvado das metricas de validacao e treino\n",
      "Pasta output/metricas/valid/fold_1 ja existe.\n",
      "Metricas salvas em output/metricas/valid/fold_1 com os nomes predict_label_valid_fold_1.npy e true_label_valid_fold_1.npy e tamanhos (5, 10, 5) e (5, 10, 5)\n",
      "Pasta output/metricas/train/fold_1 ja existe.\n",
      "Metricas salvas em output/metricas/train/fold_1 com os nomes predict_label_train_fold_1.npy e true_label_train_fold_1.npy e tamanhos (5, 10, 5) e (5, 10, 5)\n",
      "Finalizado o salvamento das metricas\n",
      "\n",
      "      ###############################################\n",
      "      Fim do treinamento com K-Fold Cross Validation\n",
      "      ###############################################\n",
      "      \n",
      "Treinamento com K-Fold Cross Validation concluído com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## create first model.\n",
    "print('''\n",
    "      ###############################################\n",
    "      Inicio do treinamento com K-Fold Cross Validation\n",
    "      ###############################################\n",
    "      ''')\n",
    "device = 'cuda:0'\n",
    "    \n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    #print(f\"  Train: index={train_index}\")\n",
    "    #print(f\"  Test:  index={test_index}\")\n",
    "    ## init train test for folder\n",
    "    train_dataset_part = Subset( train_dataset, train_index)\n",
    "    val_dataset_part = Subset( train_dataset, test_index)\n",
    "\n",
    "    train_loader_img = DataLoader(train_dataset_part, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader_img = DataLoader(val_dataset_part, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    model= ECGClassifierResnet( num_classes=1)\n",
    "    if (flg_salvar_modelos):\n",
    "        salvar_model(model, path='output/modelos', name_file=f'model_fold_{i}.pth')\n",
    "    print(f'Train and valid for Fold {i}')\n",
    "    t, l,_,outputs,labels = simple_loop(model, train_loader_img,val_loader_img, epochs, batch_size = BATCH_SIZE, fold_index =i)\n",
    "    ## Evaluate model.\n",
    "    train_loss_total.append(t)\n",
    "    val_loss_total.append(l)\n",
    "\n",
    "print('''\n",
    "      ###############################################\n",
    "      Fim do treinamento com K-Fold Cross Validation\n",
    "      ###############################################\n",
    "      ''')\n",
    "print(\"Treinamento com K-Fold Cross Validation concluído com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f4f10",
   "metadata": {},
   "source": [
    "## Métricas de Avaliacao dos modelos\n",
    "\n",
    "Acuracia\n",
    "\n",
    "Precisao\n",
    "\n",
    "Sensibilidade\n",
    "\n",
    "Especificidade\n",
    "\n",
    "F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70a0dd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Leitura de métricas salvas\n",
    "import numpy as np\n",
    "predict_label_0 = np.load('output/metricas/train/fold_0/predict_label_train_fold_0.npy')\n",
    "true_label_0 = np.load('output/metricas/train/fold_0/true_label_train_fold_0.npy')\n",
    "# --- IGNORE ---\n",
    "#print(true_label_0[1][0][0])\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "len(predict_label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb8ce677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0],\n",
       "        [0, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 1, 0]],\n",
       "\n",
       "       [[0, 1, 0, 1, 1],\n",
       "        [0, 1, 1, 1, 0],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 1]],\n",
       "\n",
       "       [[0, 0, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1]],\n",
       "\n",
       "       [[1, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [0, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 1]],\n",
       "\n",
       "       [[1, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 1]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92e2df49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[ 0  0  0  0  1]\n",
      "  [ 0  0  0  0  1]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 1  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 1  0  0  0  0]\n",
      "  [ 0  1  0  0  1]]\n",
      "\n",
      " [[ 1  0  0  0  0]\n",
      "  [ 1  0  0  1  0]\n",
      "  [ 0  1  1 -1 -1]\n",
      "  [-1  1  0  0  0]\n",
      "  [ 0  1  0  0 -1]\n",
      "  [-1  1 -1  1  1]\n",
      "  [ 1 -1 -1  0  2]\n",
      "  [ 0  0  0  0  2]\n",
      "  [-1  1  0  0  1]\n",
      "  [-1  1  0  0  1]]\n",
      "\n",
      " [[ 1  0 -2  1  1]\n",
      "  [ 2 -1 -1  3 -1]\n",
      "  [-2  2  2 -2  2]\n",
      "  [-1  0  0  3  0]\n",
      "  [-1  0  0  3  0]\n",
      "  [ 1  1  0  2 -3]\n",
      "  [-1  2 -1  3 -1]\n",
      "  [ 4 -2 -1  3 -2]\n",
      "  [-2  0  1  2  1]\n",
      "  [-1  2  2 -2  0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predict_label_0)\n",
    "len(predict_label_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1251295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for batch 0: 0.6931471228599548\n",
      "Loss for batch 1: 0.6931471228599548\n",
      "Loss for batch 2: 0.6475609540939331\n",
      "Loss for batch 3: 0.4805556833744049\n",
      "Loss for batch 4: 0.2919488847255707\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predict_label_0)):\n",
    "    outputs_tensor = torch.tensor(predict_label_0[i]).to(torch.float)\n",
    "    labels_tensor = torch.tensor(true_label_0[i]).to(torch.float)\n",
    "    loss = criterio(outputs_tensor, labels_tensor)\n",
    "    print(f'Loss for batch {i}: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9399a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2821440 2821440 2821440 2821440 2821440]\n",
      "  [3546063 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 4119212]\n",
      "  [2821440 2821440 3188174 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2471002]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [3436914 2821440 2821440 2821440 3913112]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 3827248 2821440 2821440]\n",
      "  [2821440 2821440 2631008 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2514506 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2847649 2821440 3869186 2821440]\n",
      "  [2759107 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 2821440]\n",
      "  [2821440 2821440 2821440 2821440 3113366]\n",
      "  [2821440 2821440 2821440 2821440 3379505]]\n",
      "\n",
      " [[    564     564    1204     564     564]\n",
      "  [    564     564     564     564     539]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     394     564     564     564]\n",
      "  [    564     564    1160     564     564]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     564     564     508     564]\n",
      "  [    564     264     564     564     564]\n",
      "  [    564     564     564     564    1093]\n",
      "  [    564     564    1578     564     564]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     564    2208     564     564]\n",
      "  [    564     564     564    1628     564]\n",
      "  [    564     564     564    1815     564]\n",
      "  [    564     564     564     564     564]\n",
      "  [    666     564     564     564     564]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     564     564     564    2193]\n",
      "  [    564     564     564     564     564]\n",
      "  [    564     564     564     169     676]]]\n",
      "[[0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1]\n",
      " [1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#### Leitura de métricas salvas\n",
    "import numpy as np\n",
    "predict_label_0_valid= np.load('/Users/leonardocipriani/Documents/dev/python/Artificial Intelligence Projects/oca-ia/incor_env/output/metricas/valid/fold_0/predict_label_valid_fold_0.npy')\n",
    "true_label_0_valid= np.load('/Users/leonardocipriani/Documents/dev/python/Artificial Intelligence Projects/oca-ia/incor_env/output/metricas/valid/fold_0/true_label_valid_fold_0.npy')\n",
    "# --- IGNORE ---\n",
    "print(predict_label_0_valid)\n",
    "print(true_label_0_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc67921",
   "metadata": {},
   "source": [
    "## Criacao graficos de treinamento e validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criar graficos de treinamento e validacao\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_loss_total[i], label='Train Loss')\n",
    "    plt.plot(val_loss_total[i], label='Validation Loss')\n",
    "    plt.title(f'Fold {i} - Train and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'output/graficos/loss_fold_{i}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdd0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source incor_env/Scripts/activate\n"
     ]
    }
   ],
   "source": [
    "activate_script = os.path.join(\"incor_env\", \"Scripts\", \"activate\")\n",
    "if os.name == 'nt':  # Windows\n",
    "    activate_command = f\"{activate_script}\"\n",
    "else:  # macOS/Linux\n",
    "    activate_command = f\"source {activate_script}\"\n",
    "print(activate_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86485574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando ambiente virtual...\n",
      "total 1680\n",
      "drwxr-xr-x@ 19 leonardocipriani  staff     608 Dec 14 10:14 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 16 leonardocipriani  staff     512 Nov 25 13:15 \u001b[34m..\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 16 leonardocipriani  staff     512 Dec 14 10:01 \u001b[34m.git\u001b[m\u001b[m\n",
      "-rw-r--r--   1 leonardocipriani  staff      13 Sep 13 17:55 .gitignore\n",
      "drwxr-xr-x   7 leonardocipriani  staff     224 Dec 14 10:14 \u001b[34m.incor_env\u001b[m\u001b[m\n",
      "drwxr-xr-x   4 leonardocipriani  staff     128 Dec 13 16:10 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "drwxr-xr-x   9 leonardocipriani  staff     288 Oct 14 20:26 \u001b[34m.venv\u001b[m\u001b[m\n",
      "-rw-r--r--   1 leonardocipriani  staff    1967 Dec 11 07:20 README.md\n",
      "-rw-r--r--   1 leonardocipriani  staff  683671 Dec  7 10:06 classificador_ml.ipynb\n",
      "-rw-r--r--   1 leonardocipriani  staff   70005 Dec 14 10:15 classificador_oca copy.ipynb\n",
      "-rw-r--r--   1 leonardocipriani  staff   84135 Dec 13 16:18 classificador_oca.ipynb\n",
      "drwxr-xr-x   9 leonardocipriani  staff     288 Dec 13 16:18 \u001b[34mdataset\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 leonardocipriani  staff     632 Sep  3 16:31 exemplo_csv.csv\n",
      "drwxr-xr-x   3 leonardocipriani  staff      96 Sep 28 18:46 \u001b[34mimgs\u001b[m\u001b[m\n",
      "drwxr-xr-x   9 leonardocipriani  staff     288 Dec 13 18:58 \u001b[34mincor_env\u001b[m\u001b[m\n",
      "drwxr-xr-x   4 leonardocipriani  staff     128 Dec  7 10:06 \u001b[34mlib\u001b[m\u001b[m\n",
      "drwxr-xr-x   3 leonardocipriani  staff      96 Sep  9 01:39 \u001b[34mmodels\u001b[m\u001b[m\n",
      "drwxr-xr-x   5 leonardocipriani  staff     160 Dec  7 10:06 \u001b[34moutput\u001b[m\u001b[m\n",
      "-rw-r--r--   1 leonardocipriani  staff     133 Dec  7 10:06 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def config_venv():\n",
    "    print(\"Criando ambiente virtual...\")\n",
    "    os.system(\"ls -la\")    \n",
    "    os.system(\"python -m venv .incor_env\")\n",
    "\n",
    "config_venv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870787b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_file = pd.read_csv('dataset/oca_incor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file.rename(columns={ds_file.columns[0]:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>image16.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>image16.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>image16.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>image16.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>image16.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  label\n",
       "0     image1.png      0\n",
       "1     image2.png      0\n",
       "2     image3.png      1\n",
       "3     image4.png      1\n",
       "4     image5.png      1\n",
       "..           ...    ...\n",
       "211  image16.png      1\n",
       "212  image16.png      0\n",
       "213  image16.png      0\n",
       "214  image16.png      1\n",
       "215  image16.png      1\n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
